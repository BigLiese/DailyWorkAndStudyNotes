1. 看算法图解到 38 页
   Notes：
   #ARRAY
   1> "Earth-shattering" is an idiomatic expression used to describe something that is extremely important or significant, often implying that it has a large impact or influence. It suggests that something is so significant that it could cause the earth to shake or tremble. For example, "The discovery of a cure for cancer would be an earth-shattering breakthrough in the medical field."

   2> "Flaky" is an adjective used to describe something that is unreliable or inconsistent. It can be used to describe a person, product, or process that fails to work as expected or consistently produces unpredictable or varying results. For example, "The software has been acting flaky lately, crashing unexpectedly and producing inconsistent results.

3> 4 basic ways of using data structures:

- Read
- Search
- Insert
- Delete

> when we measure how “fast” an operation takes, we do not refer to how fast the operation takes in terms of pure time, but instead in how many steps it takes.

1. A computer can jump to any memory address in one step. (Think of this as driving to 123 Main Street—you can drive there in one trip since you know exactly where it is.)
2. Recorded in each array is the memory address which it begins at. So the computer has this starting address readily.
3. Every array begins at index 0.

--> Reading from an array actually takes just _one step_. This is because the computer has the ability to jump to any particular index in the array and peer inside.

--> search operation—in which the computer checks each cell one at a time—is known as _linear search_.

For N cells in an array, linear search will take a maximum of N steps.

--> insertion in a worst-case scenario can take _up to N + 1 steps_ for an array containing N elements. This is because the worst-case scenario is inserting a value into the beginning of the array in which there are N shifts (every data element of the array) and one insertion.

--> delete for an array containing N elements, the maximum number of steps that deletion would take is _N steps_.

---

#SET
A set is a data structure that does not allow duplicate values to be contained within it.

--> Reading from a set is exactly the same as reading from an array—it takes just one step for the computer to look up what is contained within a particular index

-->Searching a set also turns out to be no different than searching an array—it takes up to _N steps_ to search to see if a value exists within a set.

--> Insertion, insertion into a set in a best-case scenario will take _N + 1 steps_ for N elements. This is because there are N steps of search to ensure that the value doesn’t already exist within the set, and then one step for the actual insertion.

In a worst-case scenario, where we’re inserting a value at the beginning of a set, the computer needs to search N cells to ensure that the set doesn’t already contain that value, and then another N steps to shift all the data to the right, and another final step to insert the new value. That’s a total of _2N + 1 steps_.

-->deletion is also identical between a set and an array—it takes up to _N steps_ to delete a value and move data to the left to close the gap.

---

**Chapter 2 Why Algorithms Matter**

An algorithm is simply a particular process for solving a problem.

> Ordered Arrays: the values of the array remain sorted.

when inserting into an ordered array, we need to always conduct _a search before the actual insertion_ to determine the correct spot for the insertion. That is one key difference (in terms of efficiency) between a standard array and an ordered array.

The major advantage of an ordered array over a standard array is that we have the option of performing a binary search rather than a linear search.

> Binary Search: find the midpoint between the upper and lower bounds

First, we establish the lower and upper bounds of where the value we're searching for can be. To start, the lower bound is the first value in the array, while the upper bound is the last value.

When we use binary search, however, each guess we make eliminates half of the possible cells we’d have to search. In our very first guess, we get to eliminate a whopping fifty cells.

[[binary search.png]]

for every time we double the data, the binary search algorithm adds a maximum of just one more step.

> Binary Search vs. Linear Search

With an array containing one hundred values, here are the maximum numbers of steps it would take for each type of search: Linear search: one hundred steps Binary search: seven steps

[[Binary Search vs. Linear Search.png]]

---

**Chapter 3 Oh Yes! Big O Notation：Count the Steps**

Instead of focusing on units of time, Big O achieves consistency by focusing only on the number of steps that an algorithm takes.

Reading from an array takes just one step, no matter how large the array is. The way to express this in Big O Notation is: O(1)

Let’s examine how Big O Notation would describe the efficiency of linear search：
In a worst-case scenario, linear search will take as many steps as there are elements in the array.

The appropriate way to express this in Big O Notation is：O(N) [pronounced as “Oh of N.”]

Big O answers the following question: how does the number of steps change as the data increases?

> Constant Time vs. Linear Time

[[Constant Time vs. Linear Time.png]]

Even though the algorithm technically takes three steps rather than one step, Big O Notation considers that trivial. O(1) is the way to describe any algorithm that doesn’t change its number of steps even when the data increases.

O(N) is considered to be, on the whole, less efficient than O(1).

> Binary search in Big O

In Big O, we describe binary search as having a time complexity of: O(log N)
[pronounced as “Oh of log N.”]
[Log is shorthand for logarithm.]
[Whenever we say O(log N), it’s actually shorthand for saying O(log2 N). We’re just omitting that small 2 for convenience.]

O(log N) is the Big O way of describing an algorithm that increases one step each time the data is doubled.

[[O(logN) O(1) O(N).png]]

[[Logarithms.png]]

---

**Chapter 4 Speeding Up Your Code with Big O**

> Bubble Sort

Given an array of unsorted numbers, how can we sort them so that they end up in ascending order?

If we get through an entire passthrough without having to make any swaps, we’ll know that the array is completely sorted.

The Bubble Sort algorithm contains two kinds of steps:

Comparisons: two numbers are compared with one another to determine which is greater.
Swaps: two numbers are swapped with one another in order to sort them.

For N elements, we make (N - 1) + (N - 2) + (N - 3) … + 1 comparisons.

In Big O Notation, we would say that Bubble Sort has an efficiency of _O(N2 )_.
In an O(N2 ) algorithm, for N data elements, there are roughly _N2 steps._

[[O(N^2).png]]

[O(N2 ) is also referred to as quadratic time]

A common example of an algorithm with quadratic time complexity is a *nested loop*
